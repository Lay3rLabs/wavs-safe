package wavs:agent;

interface client {
  use errors.{agent-error};
  use common.{message, tool, tool-call, custom-tool-handler};
  use contracts.{transaction};
  use config.{config, llm-options};

  /// Response from an LLM interaction
  variant llm-response {
    /// Transaction to be executed
    transaction(transaction),
    /// Text response (when no action is needed)
    text(string),
  }

  /// Client for making LLM API requests
  resource llm-client {
    /// Create a new LLM client with default configuration
    new: func(model: string) -> result<llm-client, agent-error>;

    /// Create a new LLM client from a JSON configuration string
    from-json: func(model: string, json-config: string) -> result<llm-client, agent-error>;

    /// Create a new LLM client with custom configuration
    with-config: func(model: string, config: llm-options) -> result<llm-client, agent-error>;

    /// Get the model name
    get-model: func() -> string;

    /// Get a reference to the current configuration
    get-config: func() -> llm-options;

    /// Send a chat completion request, with optional tools
    chat-completion: func(messages: list<message>, tools: option<list<tool>>) -> result<message, agent-error>;

    /// Helper method to get just the content string from a chat completion
    chat-completion-text: func(messages: list<message>) -> result<string, agent-error>;

    /// Process a prompt with the LLM and return either a Transaction or text response
    process-prompt: func(
      prompt: string,
      config: config,
      custom-tools: option<list<tool>>,
      custom-handlers: option<list<custom-tool-handler>>
    ) -> result<llm-response, agent-error>;
  }
}
