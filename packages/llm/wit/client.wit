package wavs:agent@0.0.1;

interface client {
  use errors.{agent-error};
  use types.{message, tool, tool-call, custom-tool-handler, llm-response, transaction, config, llm-options, llm-client};

  /// Create a new LLM client with default configuration
  new-client: func(model: string) -> result<llm-client, agent-error>;

  /// Create a new LLM client from a JSON configuration string
  from-json: func(model: string, json-config: string) -> result<llm-client, agent-error>;

  /// Create a new LLM client with custom configuration
  with-config: func(model: string, config: llm-options) -> result<llm-client, agent-error>;

  /// Client for making LLM API requests
  resource llm-client-manager {
    /// Get the model name
    get-model: func() -> string;

    /// Get a reference to the current configuration
    get-config: func() -> llm-options;

    /// Send a chat completion request, with optional tools
    chat-completion: func(messages: list<message>, tools: option<list<tool>>) -> result<message, agent-error>;

    /// Helper method to get just the content string from a chat completion
    chat-completion-text: func(messages: list<message>) -> result<string, agent-error>;

    /// Process a prompt with the LLM and return either a Transaction or text response
    process-prompt: func(
      prompt: string,
      config: config,
      custom-tools: option<list<tool>>,
      custom-handlers: option<list<custom-tool-handler>>
    ) -> result<llm-response, agent-error>;
  }
}
